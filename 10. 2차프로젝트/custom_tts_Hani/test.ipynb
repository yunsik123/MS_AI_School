{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project created. project id: test1\n",
      "can't find file 'audio_file_path' = TestData/sample_VoiceTalentVerbalStatement.wav\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# Copyright (c) Microsoft. All rights reserved.\n",
    "# Licensed under the MIT license. See LICENSE.md file in the project root for full license information.\n",
    "\n",
    "import json\n",
    "import requests\n",
    "from time import sleep\n",
    "import os\n",
    "import logging\n",
    "try:\n",
    "    import customvoice\n",
    "except ImportError:\n",
    "    print('Pleae copy folder https://github.com/Azure-Samples/cognitive-services-speech-sdk/tree/master/samples/custom-voice/python/customvoice and keep the same folder structure as github.' )\n",
    "    quit()\n",
    "import azure.cognitiveservices.speech as speechsdk\n",
    "\n",
    "\n",
    "def create_personal_voice(project_id: str,\n",
    "                          consent_id: str, consent_file_path: str, voice_talent_name: str, company_name: str,\n",
    "                          personal_voice_id: str, audio_folder: str):\n",
    "    # create project\n",
    "    project = customvoice.Project.create(config, project_id, customvoice.ProjectKind.PersonalVoice)\n",
    "    print('Project created. project id: %s' % project.id)\n",
    "\n",
    "    # upload consent\n",
    "    consent = customvoice.Consent.create(config, project_id, consent_id, voice_talent_name, company_name, consent_file_path, 'en-us')\n",
    "    if consent.status == customvoice.Status.Failed:\n",
    "        print('Create consent failed. consent id: %s' % consent.id)\n",
    "        raise Exception\n",
    "    elif consent.status == customvoice.Status.Succeeded:\n",
    "        print('Create consent succeeded. consent id: %s' % consent.id)\n",
    "\n",
    "    # create personal voice\n",
    "    personal_voice = customvoice.PersonalVoice.create(config, project_id, personal_voice_id, consent_id, audio_folder)\n",
    "    if personal_voice.status == customvoice.Status.Failed:\n",
    "        print('Create personal voice failed. personal voice id: %s' % personal_voice.id)\n",
    "        raise Exception\n",
    "    elif personal_voice.status == customvoice.Status.Succeeded:\n",
    "        print('Create personal voice succeeded. personal voice id: %s, speaker profile id: %s' % (personal_voice.id, personal_voice.speaker_profile_id))\n",
    "    return personal_voice.speaker_profile_id\n",
    "\n",
    "\n",
    "def speech_synthesis_to_wave_file(text: str, output_file_path: str, speaker_profile_id: str):\n",
    "    # Creates an instance of a speech config with specified subscription key and service region.\n",
    "    speech_config = speechsdk.SpeechConfig(subscription=config.key, region=config.region)\n",
    "    speech_config.set_speech_synthesis_output_format(speechsdk.SpeechSynthesisOutputFormat.Riff24Khz16BitMonoPcm)\n",
    "    file_config = speechsdk.audio.AudioOutputConfig(filename=output_file_path)\n",
    "    speech_synthesizer = speechsdk.SpeechSynthesizer(speech_config=speech_config, audio_config=file_config)\n",
    "\n",
    "\n",
    "    # use PhoenixLatestNeural if you want word boundary event.  We will support events on DragonLatestNeural in the future.\n",
    "    ssml = \"<speak version='1.0' xml:lang='en-US' xmlns='http://www.w3.org/2001/10/synthesis' \" \\\n",
    "           \"xmlns:mstts='http://www.w3.org/2001/mstts'>\" \\\n",
    "           \"<voice name='DragonLatestNeural'>\" \\\n",
    "           \"<mstts:ttsembedding speakerProfileId='%s'/>\" \\\n",
    "           \"<mstts:express-as style='Prompt'>\" \\\n",
    "           \"<lang xml:lang='en-US'> %s </lang>\" \\\n",
    "           \"</mstts:express-as>\" \\\n",
    "           \"</voice></speak> \" % (speaker_profile_id, text)\n",
    "\n",
    "    def word_boundary(evt):\n",
    "        print(f\"Word Boundary: Text='{evt.text}', Audio offset={evt.audio_offset / 10000}ms, Duration={evt.duration / 10000}ms, text={evt.text}\")\n",
    "\n",
    "    speech_synthesizer.synthesis_word_boundary.connect(word_boundary)\n",
    "    result = speech_synthesizer.speak_ssml_async(ssml).get()\n",
    "\n",
    "    # Check result\n",
    "    if result.reason == speechsdk.ResultReason.SynthesizingAudioCompleted:\n",
    "        print(\"Speech synthesized for text [{}], and the audio was saved to [{}]\".format(text, output_file_path))\n",
    "        print(\"result id: {}\".format(result.result_id))\n",
    "    elif result.reason == speechsdk.ResultReason.Canceled:\n",
    "        cancellation_details = result.cancellation_details\n",
    "        print(\"Speech synthesis canceled: {}\".format(cancellation_details.reason))\n",
    "        if cancellation_details.reason == speechsdk.CancellationReason.Error:\n",
    "            print(\"Error details: {}\".format(cancellation_details.error_details))\n",
    "            print(\"result id: {}\".format(result.result_id))\n",
    "\n",
    "\n",
    "def clean_up(project_id: str, consent_id: str, personal_voice_id: str):\n",
    "    customvoice.PersonalVoice.delete(config, personal_voice_id)\n",
    "    customvoice.Consent.delete(config, consent_id)\n",
    "    customvoice.Project.delete(config, project_id)\n",
    "\n",
    "\n",
    "region = 'eastus' # eastus, westeurope, southeastasia\n",
    "key = '303e8feb39e949be9df0929bc0c93390'\n",
    "\n",
    "\n",
    "logging.basicConfig(filename=\"customvoice.log\",\n",
    "                    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
    "                    filemode='w')\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "config = customvoice.Config(key, region, logger)\n",
    "\n",
    "\n",
    "# project_id = 'personal-voice-project-1'\n",
    "# consent_id = 'personal-voice-consent-1'\n",
    "# personal_voice_id  = 'personal-voice-1'\n",
    "project_id = 'test1'\n",
    "consent_id = 'test1'\n",
    "personal_voice_id  = 'test-speaker'\n",
    "\n",
    "try:\n",
    "    # step 1: create personal voice\n",
    "    # Need consent file and audio file to create personal vocie.\n",
    "    # This is consent file template.\n",
    "    # I [voice talent name] am aware that recordings of my voice will be used by [company name] to create and use a synthetic version of my voice.\n",
    "    # You can find sample consent file here\n",
    "    # https://github.com/Azure-Samples/Cognitive-Speech-TTS/blob/master/CustomVoice/Sample%20Data/Individual%20utterances%20%2B%20matching%20script/VoiceTalentVerbalStatement.wav\n",
    "    consent_file_path = r'TestData/sample_VoiceTalentVerbalStatement.wav'\n",
    "    voice_talent_name = 'Sample Voice Actor'\n",
    "    company_name = 'contoso'\n",
    "\n",
    "    # Need 5 - 90 seconds audio file.\n",
    "    # You can find sample audio file here.\n",
    "    # https://github.com/Azure-Samples/Cognitive-Speech-TTS/blob/master/CustomVoice/Sample%20Data/Individual%20utterances%20%2B%20matching%20script/SampleAudios.zip\n",
    "    audio_folder = r'TestData/voice/'\n",
    "    speaker_profile_id = create_personal_voice(project_id, \n",
    "                                            consent_id, consent_file_path, voice_talent_name, company_name,\n",
    "                                            personal_voice_id, audio_folder)\n",
    "\n",
    "    # step 2: synthesis wave\n",
    "    text = 'This is zero shot voice. Test 2.'\n",
    "    output_wave_file_path = 'output_sdk.wav'\n",
    "    speech_synthesis_to_wave_file(text, output_wave_file_path, speaker_profile_id)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "finally:\n",
    "    # Optional step 3: clean up, if you don't need this voice to synthesis more content.\n",
    "    clean_up(project_id, consent_id, personal_voice_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_up(project_id, consent_id, personal_voice_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project created. project id: test1\n",
      "Create consent succeeded. consent id: test1\n",
      "Create personal voice succeeded. personal voice id: test-speaker, speaker profile id: 8980e75e-304f-4cc2-88e7-5b3519860f84\n",
      "Speech synthesized for text [안녕하세요? 상쾌한 수요일 아침입니다.], and the audio was saved to [output_sdk.wav]\n",
      "result id: bfb4e94d3a8445598ec2def05ad51d95\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# Copyright (c) Microsoft. All rights reserved.\n",
    "# Licensed under the MIT license. See LICENSE.md file in the project root for full license information.\n",
    "\n",
    "import json\n",
    "import requests\n",
    "from time import sleep\n",
    "import os\n",
    "import logging\n",
    "try:\n",
    "    import customvoice\n",
    "except ImportError:\n",
    "    print('Pleae copy folder https://github.com/Azure-Samples/cognitive-services-speech-sdk/tree/master/samples/custom-voice/python/customvoice and keep the same folder structure as github.' )\n",
    "    quit()\n",
    "import azure.cognitiveservices.speech as speechsdk\n",
    "\n",
    "\n",
    "def create_personal_voice(project_id: str,\n",
    "                          consent_id: str, consent_file_path: str, voice_talent_name: str, company_name: str,\n",
    "                          personal_voice_id: str, audio_folder: str):\n",
    "    # create project\n",
    "    project = customvoice.Project.create(config, project_id, customvoice.ProjectKind.PersonalVoice)\n",
    "    print('Project created. project id: %s' % project.id)\n",
    "\n",
    "    # upload consent\n",
    "    consent = customvoice.Consent.create(config, project_id, consent_id, voice_talent_name, company_name, consent_file_path, 'ko-KR')\n",
    "    if consent.status == customvoice.Status.Failed:\n",
    "        print('Create consent failed. consent id: %s' % consent.id)\n",
    "        raise Exception\n",
    "    elif consent.status == customvoice.Status.Succeeded:\n",
    "        print('Create consent succeeded. consent id: %s' % consent.id)\n",
    "\n",
    "    # create personal voice\n",
    "    personal_voice = customvoice.PersonalVoice.create(config, project_id, personal_voice_id, consent_id, audio_folder)\n",
    "    if personal_voice.status == customvoice.Status.Failed:\n",
    "        print('Create personal voice failed. personal voice id: %s' % personal_voice.id)\n",
    "        raise Exception\n",
    "    elif personal_voice.status == customvoice.Status.Succeeded:\n",
    "        print('Create personal voice succeeded. personal voice id: %s, speaker profile id: %s' % (personal_voice.id, personal_voice.speaker_profile_id))\n",
    "    return personal_voice.speaker_profile_id\n",
    "\n",
    "\n",
    "def speech_synthesis_to_wave_file(text: str, output_file_path: str, speaker_profile_id: str):\n",
    "    # Creates an instance of a speech config with specified subscription key and service region.\n",
    "    speech_config = speechsdk.SpeechConfig(subscription=config.key, region=config.region)\n",
    "    speech_config.set_speech_synthesis_output_format(speechsdk.SpeechSynthesisOutputFormat.Riff24Khz16BitMonoPcm)\n",
    "    file_config = speechsdk.audio.AudioOutputConfig(filename=output_file_path)\n",
    "    speech_synthesizer = speechsdk.SpeechSynthesizer(speech_config=speech_config, audio_config=file_config)\n",
    "\n",
    "\n",
    "    # use PhoenixLatestNeural if you want word boundary event.  We will support events on DragonLatestNeural in the future.\n",
    "    ssml = \"<speak version='1.0' xml:lang='ko-KR' xmlns='http://www.w3.org/2001/10/synthesis' \" \\\n",
    "           \"xmlns:mstts='http://www.w3.org/2001/mstts'>\" \\\n",
    "           \"<voice name='DragonLatestNeural'>\" \\\n",
    "           \"<mstts:ttsembedding speakerProfileId='%s'/>\" \\\n",
    "           \"<mstts:express-as style='Prompt'>\" \\\n",
    "           \"<lang xml:lang='ko-KR'> %s </lang>\" \\\n",
    "           \"</mstts:express-as>\" \\\n",
    "           \"</voice></speak> \" % (speaker_profile_id, text)\n",
    "\n",
    "    def word_boundary(evt):\n",
    "        print(f\"Word Boundary: Text='{evt.text}', Audio offset={evt.audio_offset / 10000}ms, Duration={evt.duration / 10000}ms, text={evt.text}\")\n",
    "\n",
    "    speech_synthesizer.synthesis_word_boundary.connect(word_boundary)\n",
    "    result = speech_synthesizer.speak_ssml_async(ssml).get()\n",
    "\n",
    "    # Check result\n",
    "    if result.reason == speechsdk.ResultReason.SynthesizingAudioCompleted:\n",
    "        print(\"Speech synthesized for text [{}], and the audio was saved to [{}]\".format(text, output_file_path))\n",
    "        print(\"result id: {}\".format(result.result_id))\n",
    "    elif result.reason == speechsdk.ResultReason.Canceled:\n",
    "        cancellation_details = result.cancellation_details\n",
    "        print(\"Speech synthesis canceled: {}\".format(cancellation_details.reason))\n",
    "        if cancellation_details.reason == speechsdk.CancellationReason.Error:\n",
    "            print(\"Error details: {}\".format(cancellation_details.error_details))\n",
    "            print(\"result id: {}\".format(result.result_id))\n",
    "\n",
    "\n",
    "def clean_up(project_id: str, consent_id: str, personal_voice_id: str):\n",
    "    customvoice.PersonalVoice.delete(config, personal_voice_id)\n",
    "    customvoice.Consent.delete(config, consent_id)\n",
    "    customvoice.Project.delete(config, project_id)\n",
    "\n",
    "\n",
    "region = 'eastus' # eastus, westeurope, southeastasia\n",
    "key = '303e8feb39e949be9df0929bc0c93390'\n",
    "\n",
    "\n",
    "logging.basicConfig(filename=\"customvoice.log\",\n",
    "                    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
    "                    filemode='w')\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "config = customvoice.Config(key, region, logger)\n",
    "\n",
    "\n",
    "# project_id = 'personal-voice-project-1'\n",
    "# consent_id = 'personal-voice-consent-1'\n",
    "# personal_voice_id  = 'personal-voice-1'\n",
    "project_id = 'test1'\n",
    "consent_id = 'test1'\n",
    "personal_voice_id  = 'test-speaker'\n",
    "\n",
    "try:\n",
    "    # step 1: create personal voice\n",
    "    # Need consent file and audio file to create personal vocie.\n",
    "    # This is consent file template.\n",
    "    # I [voice talent name] am aware that recordings of my voice will be used by [company name] to create and use a synthetic version of my voice.\n",
    "    # You can find sample consent file here\n",
    "    # https://github.com/Azure-Samples/Cognitive-Speech-TTS/blob/master/CustomVoice/Sample%20Data/Individual%20utterances%20%2B%20matching%20script/VoiceTalentVerbalStatement.wav\n",
    "    consent_file_path = r'TestData/동의.wav'\n",
    "    voice_talent_name = '서예건'\n",
    "    company_name = '하니바람'\n",
    "\n",
    "    # Need 5 - 90 seconds audio file.\n",
    "    # You can find sample audio file here.\n",
    "    # https://github.com/Azure-Samples/Cognitive-Speech-TTS/blob/master/CustomVoice/Sample%20Data/Individual%20utterances%20%2B%20matching%20script/SampleAudios.zip\n",
    "    audio_folder = r'TestData/voice/'\n",
    "    speaker_profile_id = create_personal_voice(project_id, \n",
    "                                            consent_id, consent_file_path, voice_talent_name, company_name,\n",
    "                                            personal_voice_id, audio_folder)\n",
    "\n",
    "    # step 2: synthesis wave\n",
    "    text = '안녕하세요? 상쾌한 수요일 아침입니다.'\n",
    "    output_wave_file_path = 'output_sdk.wav'\n",
    "    speech_synthesis_to_wave_file(text, output_wave_file_path, speaker_profile_id)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "# finally:\n",
    "#     # Optional step 3: clean up, if you don't need this voice to synthesis more content.\n",
    "#     clean_up(project_id, consent_id, personal_voice_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7863\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7863/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import requests\n",
    "\n",
    "# Azure Speech API 인증 정보\n",
    "subscription_key = \"303e8feb39e949be9df0929bc0c93390\"\n",
    "endpoint_id = \"b134f8d5-2716-4f2e-abfe-62b1705deaf9\"\n",
    "region = \"eastus\"\n",
    "\n",
    "# Azure Speech API 토큰을 얻는 함수\n",
    "def get_token():\n",
    "    endpoint = f\"https://{region}.api.cognitive.microsoft.com/sts/v1.0/issueToken\"\n",
    "    headers = {\n",
    "        \"Ocp-Apim-Subscription-Key\": subscription_key,\n",
    "    }\n",
    "\n",
    "    response = requests.post(endpoint, headers=headers)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        return response.text\n",
    "    else:\n",
    "        return ''\n",
    "\n",
    "# 텍스트를 음성으로 변환하는 함수\n",
    "def request_tts(text):\n",
    "    endpoint = f\"https://{region}.tts.speech.microsoft.com/cognitiveservices/v1\"\n",
    "    access_token = get_token()\n",
    "\n",
    "    if not access_token:\n",
    "        return None\n",
    "\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/ssml+xml\",\n",
    "        \"X-Microsoft-OutputFormat\": \"riff-24khz-16bit-mono-pcm\",\n",
    "        \"Authorization\": f\"Bearer {access_token}\"\n",
    "    }\n",
    "\n",
    "    # SSML (Speech Synthesis Markup Language) 포맷\n",
    "    # data = f\"\"\"\n",
    "    # <speak version='1.0' xml:lang='ko-KR'>\n",
    "    #     <voice xml:lang='ko-KR' xml:gender='Female' name='ko-KR-JiMinNeural'>\n",
    "    #         {text}\n",
    "    #     </voice>\n",
    "    # </speak>\n",
    "    # \"\"\"\n",
    "    data =\"<speak version='1.0' xml:lang='ko-KR' xmlns='http://www.w3.org/2001/10/synthesis' \" \\\n",
    "           \"xmlns:mstts='http://www.w3.org/2001/mstts'>\" \\\n",
    "           \"<voice name='DragonLatestNeural'>\" \\\n",
    "           \"<mstts:ttsembedding speakerProfileId='%s'/>\" \\\n",
    "           \"<mstts:express-as style='Prompt'>\" \\\n",
    "           \"<lang xml:lang='ko-KR'> %s </lang>\" \\\n",
    "           \"</mstts:express-as>\" \\\n",
    "           \"</voice></speak> \" % (speaker_profile_id, text)\n",
    "\n",
    "\n",
    "    response = requests.post(endpoint, headers=headers, data=data)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        file_name = 'response_audio.wav'\n",
    "        with open(file_name, \"wb\") as audio_file:\n",
    "            audio_file.write(response.content)\n",
    "        return file_name\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Gradio 인터페이스에서 호출되는 함수\n",
    "def click_tts(text):\n",
    "    file_name = request_tts(text)\n",
    "    if file_name:\n",
    "        return file_name\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Gradio 인터페이스 구성\n",
    "with gr.Blocks() as demo:\n",
    "    with gr.Column():\n",
    "        gr.Markdown('<h3>텍스트 음성 변환</h3>')\n",
    "        input_textbox = gr.Textbox(label=\"입력 텍스트\", placeholder=\"변환할 텍스트를 입력하세요\")\n",
    "        send_button = gr.Button(\"전송\")\n",
    "        output_audio = gr.Audio(label=\"출력 오디오\", type=\"filepath\", interactive=False)\n",
    "\n",
    "        send_button.click(fn=click_tts, inputs=[input_textbox], outputs=[output_audio])\n",
    "\n",
    "# Gradio 앱 실행\n",
    "demo.launch()\n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
