{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels Length:  80\n",
      "Running on local URL:  http://127.0.0.1:7865\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7865/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import gradio as gr\n",
    "import numpy as np\n",
    "import base64\n",
    "import requests\n",
    "\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "# #################### YOLO V3 ##############################\n",
    "\n",
    "# Yolov3 파일 경로\n",
    "weights_path = 'yolo3/yolov3.weights'\n",
    "config_path = 'yolo3/yolov3.cfg'\n",
    "names_path = 'yolo3/coco.names'\n",
    "\n",
    "# YOLOv3 모델 로드\n",
    "net = cv2.dnn.readNet(weights_path, config_path)\n",
    "\n",
    "# 라벨 이름 로드\n",
    "with open(names_path, 'r') as f:\n",
    "    labels = f.read().strip().split('\\n')\n",
    "    print('Labels Length: ', len(labels))\n",
    "\n",
    "# 객체 감지 함수\n",
    "def detect_objects(image):\n",
    "    height, width = image.shape[:2]\n",
    "    blob = cv2.dnn.blobFromImage(image, 1/255.0, (416, 416), swapRB=True, crop=False)\n",
    "    net.setInput(blob)\n",
    "    layer_names = net.getLayerNames()\n",
    "    \n",
    "    output_layers = [layer_names[i - 1] for i in net.getUnconnectedOutLayers()]\n",
    "    \n",
    "    detections = net.forward(output_layers)\n",
    "    print('Detections Length: ', len(detections))\n",
    "\n",
    "    box_list = []\n",
    "    confidence_list = []\n",
    "    class_id_list = []\n",
    "\n",
    "    for output in detections:\n",
    "        for detection in output:\n",
    "            print('Detection Length: ', len(labels))\n",
    "            scores = detection[5:]\n",
    "            class_id = np.argmax(scores)\n",
    "            confidence = scores[class_id]\n",
    "\n",
    "            if confidence > 0.5:\n",
    "                box = detection[0:4] * np.array([width, height, width, height])\n",
    "                (center_x, center_y, w, h) = box.astype(\"int\")\n",
    "                x = int(center_x - (w / 2))\n",
    "                y = int(center_y - (h / 2))\n",
    "\n",
    "                box_list.append([x, y, int(w), int(h)])\n",
    "                confidence_list.append(float(confidence))\n",
    "                class_id_list.append(class_id)\n",
    "    \n",
    "    index_list = cv2.dnn.NMSBoxes(box_list, confidence_list, 0.5, 0.4)\n",
    "    \n",
    "    if len(index_list) > 0:\n",
    "        for i in index_list.flatten():\n",
    "            x, y, w, h = box_list[i]\n",
    "            label = str(labels[class_id_list[i]])\n",
    "            confidence = confidence_list[i]\n",
    "            \n",
    "            #사각형 그리기\n",
    "            cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "            # 레이블 표시\n",
    "            cv2.putText(image, f\"{label} {(confidence*100):.2f}\", (x, y - 10), cv2.FONT_HERSHEY_COMPLEX, 2, (0, 0, 255), 2)\n",
    "\n",
    "    return image        \n",
    "#############################################################\n",
    "\n",
    "################# chatgpt_response ##########################\n",
    "\n",
    "def chatgpt_response(image_array, history):\n",
    "    endpoint = \"https://fimtrus-openai.openai.azure.com\"\n",
    "    api_key = \"310a6832c2394daf97a3f446cc86ce20\"\n",
    "    deployment_name = \"fitmrus-gpt4o\"\n",
    "\n",
    "    headers = {\n",
    "        'Content-Type': 'application/json',\n",
    "        'api-key': api_key\n",
    "    }\n",
    "\n",
    "    messages = []\n",
    "\n",
    "    #System\n",
    "    messages.append({\n",
    "        \"role\": \"system\",\n",
    "        \"content\": [{\n",
    "            \"type\": \"text\",\n",
    "            \"text\": \"너는 사진 속에서 감지된 물체에 대해서 분석하는 봇이야.\"\n",
    "        }]\n",
    "    })\n",
    "\n",
    "    image = Image.fromarray(image_array)\n",
    "    buffered_io = BytesIO()\n",
    "    image.save(buffered_io, format='png')\n",
    "    base64_image = base64.b64encode(buffered_io.getvalue()).decode(\"utf-8\")\n",
    "\n",
    "    # original_width, original_height = image.size\n",
    "    # ratio = 400 / original_width\n",
    "    # resized_image = image.resize((int(original_width * ratio), int(original_height * ratio)), Image.LANCOS)\n",
    "\n",
    "    #User\n",
    "    messages.append({\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [{\n",
    "            \"type\": \"text\",\n",
    "            \"text\": \"이 사진에서 감지된 물체에 대해 감지 확률과 함께 자세하게 설명해줘.\"\n",
    "        },{\n",
    "            \"type\": \"image_url\",\n",
    "            \"image_url\": {\n",
    "                \"url\": f\"data:image/png;base64,{base64_image}\"\n",
    "            }\n",
    "        }]\n",
    "    })\n",
    "\n",
    "    payload = {\n",
    "        \"messages\": messages,\n",
    "        \"temperature\": 0.7,\n",
    "        \"top_p\": 0.95,\n",
    "        \"max_tokens\": 800,\n",
    "    }\n",
    "\n",
    "    response = requests.post(\n",
    "        f\"{endpoint}/openai/deployments/{deployment_name}/chat/completions?api-version=2024-02-15-preview\",\n",
    "        headers=headers,\n",
    "        json=payload\n",
    "    )\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        result = response.json()\n",
    "        bot_response = result['choices'][0]['message']['content'].strip()\n",
    "        history.append(('User', bot_response))\n",
    "        return history\n",
    "    else:\n",
    "        history.append((str(response.status_code), response.text))\n",
    "        return history\n",
    "#############################################################\n",
    "\n",
    "def stream_webcam(image):\n",
    "    return detect_objects(image)\n",
    "\n",
    "def click_capture(image):\n",
    "    return image\n",
    "\n",
    "def click_send_gpt(image_array, history):\n",
    "    return chatgpt_response(image_array, history)\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "\n",
    "    gr.Markdown(\"# Fimtrus's AI World!!!\")\n",
    "\n",
    "    with gr.Column():\n",
    "\n",
    "        with gr.Row():\n",
    "            webcam_input = gr.Image(label=\"실시간 화면\", sources=\"webcam\")\n",
    "            output_image = gr.Image(label=\"실시간 감지\", interactive=False)\n",
    "            output_capture_image = gr.Image(label=\"캡쳐 화면\", interactive=False)\n",
    "\n",
    "        with gr.Row():\n",
    "            capture_button = gr.Button('캡쳐')\n",
    "            send_gpt_button = gr.Button('GPT로 전송')\n",
    "\n",
    "    with gr.Column():\n",
    "        chatbot = gr.Chatbot(label=\"분석 결과\")\n",
    "        chatbot_audio = gr.Audio(label='GPT', interactive=False)\n",
    "        # chatbot, audio \n",
    "    \n",
    "    webcam_input.stream(fn=stream_webcam, inputs=[webcam_input], outputs=[output_image])\n",
    "    capture_button.click(fn=click_capture, inputs=[output_image], outputs=[output_capture_image])\n",
    "    send_gpt_button.click(fn=click_send_gpt, inputs=[output_capture_image, chatbot], outputs=[chatbot])\n",
    "    # 실시간 화면에 대한 stream event.\n",
    "    #각종 이벤트 리스너 필요.\n",
    "\n",
    "demo.launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
